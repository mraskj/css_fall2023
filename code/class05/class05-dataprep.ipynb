{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c75265e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pyreadr\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc01a9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change working directory to our project folder - REPLACE PATH WITH YOUR OWN DIRECTORY\n",
    "# wd = 'C:\\\\Users\\\\au535365\\\\Dropbox\\\\teaching\\\\css_fall2023'\n",
    "wd = '/home/rask/Dropbox/teaching/css_fall2023'\n",
    "os.chdir(wd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16412307",
   "metadata": {},
   "source": [
    "### Prepare Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f91c0a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in R data\n",
    "rfile = '/home/rask/Dropbox/research/stigma-paper/data/00-analysis.rds'\n",
    "df = pyreadr.read_r(rfile)\n",
    "df = df[None] \n",
    "\n",
    "# Make some new columns\n",
    "red_parties = ['S', 'SF', 'EL', 'ALT', 'RV']\n",
    "blue_parties = ['V', 'KF', 'LA', 'NB', 'DF']\n",
    "df['partycolor'] = df['party'].apply(lambda x: 'red' if x in red_parties else 'blue')\n",
    "df['partyterm'] = df.apply(lambda x: x['partycolor'] + '-' + str(x['period']), axis=1)\n",
    "\n",
    "# Data cleaning\n",
    "df['period'] = df['period'].astype(int)\n",
    "df['period'] = df['period'].astype(str)\n",
    "\n",
    "parlterms = df.period.unique().tolist()\n",
    "\n",
    "for term in parlterms:\n",
    "    df_term = df.loc[df['period'] == term,].reset_index(drop=True)\n",
    "    df_term.to_csv(f'data/ft-speeches/{term}.csv', index=False)\n",
    "\n",
    "# Save\n",
    "# df.to_csv('data/ft-speeches_2000-2021.csv', index=False)\n",
    "\n",
    "#df.groupby(['partycolor', 'period']).describe()\n",
    "#df.groupby(['partyterm']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1455996",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir('data/ft-speeches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3cd8fe33",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfall = pd.DataFrame()\n",
    "for file in files:\n",
    "    df_term = pd.read_csv('data/ft-speeches/' + file)\n",
    "    dfall = pd.concat([dfall, df_term])\n",
    "dfall.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924702ff",
   "metadata": {},
   "source": [
    "### Prepare Fixed Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8db56fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define function to remove stopwords\n",
    "# def remove_stop_words(text): \n",
    "#     words = text.split() \n",
    "  \n",
    "#     words = [w for w in words if w not in stopwords] \n",
    "  \n",
    "#     return ' '.join(words)\n",
    "\n",
    "# translator = str.maketrans('', '', punctuation)\n",
    "\n",
    "# def preprocessing(raw, verbose=True):\n",
    "    \n",
    "#     # Preprocesssing of text\n",
    "#     text_list = []\n",
    "#     iterations = len(raw)\n",
    "    \n",
    "#     for i in range(iterations):\n",
    "    \n",
    "#         if i % 10000 == 0 or i == iterations - 1 & verbose:\n",
    "#             print(f\"Iteration {i} ({round(round(i / iterations, 3) * 100, 3)}% completed)\", end = \"\\r\")\n",
    "\n",
    "#         q = samples[i].replace(u'\\xa0', u' ')\n",
    "#         q = re.sub('\\d+', '', q)\n",
    "#         q = q.translate(translator)      \n",
    "#         q = remove_stop_words(q)\n",
    "#         q = q.lower()\n",
    "#         q = q.split()\n",
    "#         q = [x for x in q if len(x) > 2]\n",
    "\n",
    "#         text_list.append(q)\n",
    "#     return text_list\n",
    "\n",
    "# samples = df['text'].values.tolist()\n",
    "# text_clean = preprocessing(raw=samples)\n",
    "# text_full = [' '.join(x) for x in text_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac28410e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(decode_error='ignore', min_df = 50)\n",
    "X = vectorizer.fit_transform(df['text'])\n",
    "wordlist = vectorizer.get_feature_names_out()\n",
    "wordlist = [x for x in wordlist if not re.search(r'[0-9]', x)]\n",
    "pickle.dump(wordlist, open('data/vocab_min200.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
