{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNvjVuCKAxsll1bhnjyFcUZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mraskj/css_fall2023/blob/main/code/class10/class10-tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Class 10: Audio Measurement - Tutorial\n",
        "\n",
        "In this tutorial, we will explore how Python enables you to interact with Praat in a Pythonic way. Praat is a popular speech analysis software designed to study phonetics (the sound of speeches) using computers. It offers a way of functionalities such as speech synthesis (i.e. text-to-speech), speech manipulation, and also machine learning algorithms such as PCA. In this course, we will focus on its speech analysis capabilities, which is considered the best possible option when one wants to computationally analyze speeches using lingustic and phonetic theory.\n",
        "\n",
        "Below I have printed the same list of useful Colab shortcuts as in *class09*.\n",
        "\n",
        "- Add a text cell: `ctrl + L`\n",
        "- Add a code cell: `ctrl + K`\n",
        "- Convert to text cell: `ctrl + M M`\n",
        "- Convert to code cell: `ctrl + M Y`\n",
        "- Add code cell above: `ctrl + M A`\n",
        "- Add code cell below: `ctrl + M B`\n",
        "- Run cell and select new cell `shift + enter`\n",
        "- Run cell and insert new cell `alt + enter`\n",
        "- Run selected code `ctrl + shift + enter`\n",
        "- Run the focused cell `ctrl + enter`\n",
        "- Run all cells in notebook `ctrl + F9`\n",
        "- Run all cells before the current `ctrl + F8`\n",
        "- Run cell and all cells after `ctrl + F10`\n",
        "- Restart runtime: `ctrl + M`\n"
      ],
      "metadata": {
        "id": "wiAY2QdrgvDW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0 Setup\n",
        "\n",
        "### 0.1 Accessing GitHub\n",
        "To access the audio files from GitHub, we will start by cloning the GitHub repo into our local runtime. This can be with the terminal command:\n",
        "\n",
        "```\n",
        "!git clone https://github.com/mraskj/css_fall2023.git\n",
        "```\n",
        "\n",
        "The exclamation mark `!` specifies that we execute a terminal command within a notebook, just as we have seen previously. When the repo is cloned, it is located in */content/"
      ],
      "metadata": {
        "id": "gF4-MzQHh407"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone GitHub directory into\n",
        "!git clone https://github.com/mraskj/css_fall2023.git"
      ],
      "metadata": {
        "id": "48qFYPffiAF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 0.2 Environments and Packages\n",
        "\n",
        "Unlike local notebooks, which we typically run in local environments to keep package dependencies in check, Colab notebooks run each runtime. That means that all packages must be installed if you for instance refresh Colab. Unlike local environments, however, Colab has a bunch of preinstalled packages, but we still need to a few on certain occassions. We can do that using\n",
        "\n",
        "\n",
        "```\n",
        "!pip install -r /content/css_fall2023/requirements/FILENAME.txt\n",
        "```\n",
        "\n",
        "where *FILENAME* is the name of the file (e.g. *requirements-topic4-class9*)."
      ],
      "metadata": {
        "id": "x7WEU3nmiEbc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/css_fall2023/requirements/requirements_topic4-class9.txt"
      ],
      "metadata": {
        "id": "eoQmlk7tiIsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0.3 Importing Modules"
      ],
      "metadata": {
        "id": "f5BTBiu8kTRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing modules\n",
        "\n",
        "# For file and directory management\n",
        "import os\n",
        "\n",
        "# For regular expressions\n",
        "import re\n",
        "\n",
        "# For data handling\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# For plotting\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.set() # Use seaborn's default style to make attractive graphs\n",
        "\n",
        "# Feature extraction\n",
        "import librosa\n",
        "\n",
        "# For Praat\n",
        "import parselmouth\n",
        "\n",
        "# For math functionalities\n",
        "import math"
      ],
      "metadata": {
        "id": "pQF_s63EiRtP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0.4 Reading Data\n",
        "\n",
        "For the lab session for *class10*, we work with 20 audio files each corresponding to a speech in the Danish parliament in the second assembly of the 2007 parliamentary term (*20072*). The files come from 10 different speakers with two speeches each. FIve of the speakers are men and Five are women.\n",
        "\n",
        "You find the files in *data/audio/class10/* folder in the cloned GitHub repo."
      ],
      "metadata": {
        "id": "vUWy-mXe5Dq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define path to directory containing audio files - os.getcwd() corresponds to '/content'\n",
        "base_dir = os.path.join(os.getcwd(), 'css_fall2023/data/audio/class10')\n",
        "\n",
        "# List files in the `male` and `female` folder\n",
        "male_files = os.listdir(os.path.join(base_dir, 'male'))\n",
        "female_files = os.listdir(os.path.join(base_dir, 'female'))"
      ],
      "metadata": {
        "id": "qiIwGK66gmis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we print `male_files` and `female_files`, we'll see that they are unsorted. To keep things in order, we sort the files by the first digits in the filenames. We define a custom function for this purpose and provide the function as parameter to the `key` argument in the `sorted()` function."
      ],
      "metadata": {
        "id": "1umWsxdfg7G5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a custom sorting key function\n",
        "def digit_sort_key(v):\n",
        "\n",
        "    digits = re.search('\\d+', v)\n",
        "    return int(digits.group())\n",
        "    #if digits:\n",
        "    #    return int(digits.group())\n",
        "    #else:\n",
        "    #    return float('inf')  # Return infinity for strings with no numbers\n",
        "\n",
        "# Sort the lists\n",
        "male_files = sorted(male_files, key=digit_sort_key)\n",
        "female_files = sorted(female_files, key=digit_sort_key)\n",
        "\n",
        "# Print to see that the lists are sorted\n",
        "female_files, male_files"
      ],
      "metadata": {
        "id": "YYBkxIM9g6WF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 Praat Sound Objects\n",
        "\n",
        "In *class09*, we loaded our audio using `wavfile.read()` method from the `scipy.io` module. When we use `parselmouth-praat`, we need to explicitly tell Python that our audio file is supposed to interact with *Praat*. We do that by constructing a `parselmouth.Sound` object.\n"
      ],
      "metadata": {
        "id": "xQSBeagRkYeD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initiate sound object\n",
        "snd = parselmouth.Sound(os.path.join(base_dir, 'female', female_files[0]))\n",
        "\n",
        "print(type(snd))"
      ],
      "metadata": {
        "id": "VzfOYgW8k2jZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(snd)"
      ],
      "metadata": {
        "id": "Re2EC15Lo0vu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To see all properties and methods of the object\n",
        "dir(snd)"
      ],
      "metadata": {
        "id": "8fwpzilIqa2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#snd.sampling_frequency, snd.sampling_period\n",
        "#snd.get_number_of_samples(), snd.get_number_of_channels()\n",
        "#snd.xmin, snd.xmax, snd.get_root_mean_square, snd.get_rms\n",
        "#snd.get_total_duration()\n",
        "#snd.get_energy_in_air(), snd.get_energy()\n",
        "#snd.get_intensity()\n",
        "#snd.get_maximum(), snd.get_minimum()"
      ],
      "metadata": {
        "id": "4S-S0m4VoiL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Access time samples\n",
        "t = snd.xs()\n",
        "print(f\"Number of samples: {t.shape}\")\n",
        "print(f\"Last time sample: {t[-1]}\")\n",
        "print(type(t))"
      ],
      "metadata": {
        "id": "X9cXoyVhqfk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Access values\n",
        "amp = snd.values\n",
        "print(f\"Number of samples: {amp.shape}\")\n",
        "print(type(amp))"
      ],
      "metadata": {
        "id": "Dm6-fbvHql39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are now back in pure Python language as `t` and `amp` are both of type `numpy.ndarray`\n",
        "\n",
        "To illustrate its content, we plot a snippet of the first audio file in the `female_list` as a waveform. For the purpose, we define a function."
      ],
      "metadata": {
        "id": "8k37KpbVrKDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define function to plot a waveform\n",
        "def draw_waveform(x, y,\n",
        "                  color='#381a61',\n",
        "                  alpha=.5,\n",
        "                  xlim=[0.0, 1.0],\n",
        "                  xlabel=None,\n",
        "                  ylabel=None,\n",
        "                  show=True):\n",
        "\n",
        "  plt.figure(figsize=(7,5))\n",
        "  plt.plot(x, y, alpha=alpha, color=color)\n",
        "  plt.xlim(xlim)\n",
        "\n",
        "  if xlabel:\n",
        "    plt.xlabel(xlabel)\n",
        "\n",
        "  if ylabel:\n",
        "    plt.ylabel(ylabel)\n",
        "\n",
        "  if show:\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "shU6ibxdk52X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the first 16000 samples = 1 second of audio\n",
        "sr = snd.sampling_frequency\n",
        "start, stop = 0, 16000\n",
        "x, y = snd.xs()[start:stop], snd.values[0][start:stop].T\n",
        "draw_waveform(x,\n",
        "              y,\n",
        "              xlim=[start, stop/sr],\n",
        "              xlabel='Time (s)', ylabel='Amplitude')"
      ],
      "metadata": {
        "id": "-rWu2tZgk7B9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 Feature Extraction with Praat\n",
        "\n",
        "The `parselmouth-praat` makes it straightforward to construct audio measures from the `parselmouth.Sound` object.\n",
        "\n",
        "This can be done with two approaches:\n",
        "* `to_()`\n",
        "* `call()`\n"
      ],
      "metadata": {
        "id": "VO1s4njLjCxR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to_()\n",
        "mfccs = snd.to_mfcc(10)\n",
        "pitch = snd.to_pitch()\n",
        "harmonicity = snd.to_harmonicity()\n",
        "intensity = snd.to_intensity()\n",
        "spectrogram = snd.to_spectrogram()\n",
        "spectrum = snd.to_spectrum()"
      ],
      "metadata": {
        "id": "6R0Zd_YrjSVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# call()\n",
        "f0min, f0max = 100, 500\n",
        "pitch_obj = parselmouth.praat.call(snd, \"To Pitch\", 0.0, f0min, f0max)\n",
        "meanF0 = parselmouth.praat.call(pitch_obj, \"Get mean\", 0, 0, 'Hertz')\n",
        "stdevF0 = parselmouth.praat.call(pitch_obj, \"Get standard deviation\", 0 ,0, 'Hertz')\n",
        "maxF0 = parselmouth.praat.call(pitch_obj, \"Get maximum\", 0, 0, 'Hertz',\"None\")\n",
        "minF0 = parselmouth.praat.call(pitch_obj, \"Get minimum\", 0, 0, 'Hertz',\"None\")"
      ],
      "metadata": {
        "id": "gZ441D0uuyBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Access time samples and pitch estimates from the `pitch` object\n",
        "# pitch.xs()\n",
        "# pitch.values"
      ],
      "metadata": {
        "id": "qG089FvCjQpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use custom settings\n",
        "# pitch = snd.to_pitch(pitch_floor=100, pitch_ceiling=500)"
      ],
      "metadata": {
        "id": "NXstiXD7Cy-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) Plotting"
      ],
      "metadata": {
        "id": "hYwKkzOawe13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_spectrogram(spectrogram, dynamic_range=70):\n",
        "    X, Y = spectrogram.x_grid(), spectrogram.y_grid()\n",
        "    sg_db = 10 * np.log10(spectrogram.values)\n",
        "    plt.pcolormesh(X, Y, sg_db, vmin=sg_db.max() - dynamic_range, cmap='viridis')\n",
        "    plt.ylim([spectrogram.ymin, spectrogram.ymax])\n",
        "    plt.xlabel(\"time [s]\")\n",
        "    plt.ylabel(\"frequency [Hz]\")\n",
        "\n",
        "def draw_intensity(intensity):\n",
        "    plt.plot(intensity.xs(), intensity.values.T, linewidth=3, color='w')\n",
        "    plt.plot(intensity.xs(), intensity.values.T, linewidth=1)\n",
        "    plt.grid(False)\n",
        "    plt.ylim(0)\n",
        "    plt.ylabel(\"intensity [dB]\")\n",
        "\n",
        "def draw_pitch(pitch):\n",
        "    pitch_values = pitch.selected_array['frequency']\n",
        "    pitch_values[pitch_values==0] = np.nan\n",
        "    plt.plot(pitch.xs(), pitch_values, 'o', markersize=5, color='w')\n",
        "    plt.plot(pitch.xs(), pitch_values, 'o', markersize=2)\n",
        "    plt.grid(False)\n",
        "    plt.ylim(0, pitch.ceiling)\n",
        "    plt.ylabel(\"fundamental frequency [Hz]\")"
      ],
      "metadata": {
        "id": "7dq341HikpQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot spectrogram and intensity + spectrogram and F0\n",
        "start, stop = 3, 4\n",
        "pitch = snd.to_pitch()\n",
        "spectrogram = snd.to_spectrogram()\n",
        "intensity = snd.to_intensity()\n",
        "\n",
        "plt.figure(figsize=(24, 12))\n",
        "plt.subplot(1, 2, 1)\n",
        "draw_spectrogram(spectrogram)\n",
        "plt.twinx()\n",
        "draw_intensity(intensity)\n",
        "plt.xlim([start, stop])\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "draw_spectrogram(spectrogram)\n",
        "plt.yticks([])\n",
        "plt.twinx()\n",
        "draw_pitch(pitch)\n",
        "plt.xlim([start, stop])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nLEcxNUGkxw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to compute the speech rate of audio files\n",
        "# All credit to Dr. Feinberg (https://github.com/drfeinberg/PraatScripts/blob/master/syllable_nuclei.py)\n",
        "def speech_rate(file):\n",
        "\n",
        "    silencedb = -25\n",
        "    mindip = 2\n",
        "    minpause = 0.3\n",
        "    sound = parselmouth.Sound(file)\n",
        "    originaldur = sound.get_total_duration()\n",
        "    intensity = sound.to_intensity(50)\n",
        "    start = parselmouth.praat.call(intensity, \"Get time from frame number\", 1)\n",
        "    nframes = parselmouth.praat.call(intensity, \"Get number of frames\")\n",
        "    end = parselmouth.praat.call(intensity, \"Get time from frame number\", nframes)\n",
        "    min_intensity = parselmouth.praat.call(intensity, \"Get minimum\", 0, 0, \"Parabolic\")\n",
        "    max_intensity = parselmouth.praat.call(intensity, \"Get maximum\", 0, 0, \"Parabolic\")\n",
        "\n",
        "    # get .99 quantile to get maximum (without influence of non-speech sound bursts)\n",
        "    max_99_intensity = parselmouth.praat.call(intensity, \"Get quantile\", 0, 0, 0.99)\n",
        "\n",
        "    # estimate Intensity threshold\n",
        "    threshold = max_99_intensity + silencedb\n",
        "    threshold2 = max_intensity - max_99_intensity\n",
        "    threshold3 = silencedb - threshold2\n",
        "    if threshold < min_intensity:\n",
        "        threshold = min_intensity\n",
        "\n",
        "    # get pauses (silences) and speakingtime\n",
        "    textgrid = parselmouth.praat.call(intensity, \"To TextGrid (silences)\", threshold3, minpause, 0.1, \"silent\", \"sounding\")\n",
        "    silencetier = parselmouth.praat.call(textgrid, \"Extract tier\", 1)\n",
        "    silencetable = parselmouth.praat.call(silencetier, \"Down to TableOfReal\", \"sounding\")\n",
        "    npauses = parselmouth.praat.call(silencetable, \"Get number of rows\")\n",
        "    speakingtot = 0\n",
        "    for ipause in range(npauses):\n",
        "        pause = ipause + 1\n",
        "        beginsound = parselmouth.praat.call(silencetable, \"Get value\", pause, 1)\n",
        "        endsound = parselmouth.praat.call(silencetable, \"Get value\", pause, 2)\n",
        "        speakingdur = endsound - beginsound\n",
        "        speakingtot += speakingdur\n",
        "\n",
        "    intensity_matrix = parselmouth.praat.call(intensity, \"Down to Matrix\")\n",
        "    # sndintid = sound_from_intensity_matrix\n",
        "    sound_from_intensity_matrix = parselmouth.praat.call(intensity_matrix, \"To Sound (slice)\", 1)\n",
        "    # use total duration, not end time, to find out duration of intdur (intensity_duration)\n",
        "    # in order to allow nonzero starting times.\n",
        "    intensity_duration = parselmouth.praat.call(sound_from_intensity_matrix, \"Get total duration\")\n",
        "    intensity_max = parselmouth.praat.call(sound_from_intensity_matrix, \"Get maximum\", 0, 0, \"Parabolic\")\n",
        "    point_process = parselmouth.praat.call(sound_from_intensity_matrix, \"To PointProcess (extrema)\", \"Left\", \"yes\", \"no\", \"Sinc70\")\n",
        "    # estimate peak positions (all peaks)\n",
        "    numpeaks = parselmouth.praat.call(point_process, \"Get number of points\")\n",
        "    t = [parselmouth.praat.call(point_process, \"Get time from index\", i + 1) for i in range(numpeaks)]\n",
        "\n",
        "    # fill array with intensity values\n",
        "    timepeaks = []\n",
        "    peakcount = 0\n",
        "    intensities = []\n",
        "    for i in range(numpeaks):\n",
        "        value = parselmouth.praat.call(sound_from_intensity_matrix, \"Get value at time\", t[i], \"Cubic\")\n",
        "        if value > threshold:\n",
        "            peakcount += 1\n",
        "            intensities.append(value)\n",
        "            timepeaks.append(t[i])\n",
        "\n",
        "    # fill array with valid peaks: only intensity values if preceding\n",
        "    # dip in intensity is greater than mindip\n",
        "    validpeakcount = 0\n",
        "    currenttime = timepeaks[0]\n",
        "    currentint = intensities[0]\n",
        "    validtime = []\n",
        "\n",
        "    for p in range(peakcount - 1):\n",
        "        following = p + 1\n",
        "        followingtime = timepeaks[p + 1]\n",
        "        dip = parselmouth.praat.call(intensity, \"Get minimum\", currenttime, timepeaks[p + 1], \"None\")\n",
        "        diffint = abs(currentint - dip)\n",
        "        if diffint > mindip:\n",
        "            validpeakcount += 1\n",
        "            validtime.append(timepeaks[p])\n",
        "        currenttime = timepeaks[following]\n",
        "        currentint = parselmouth.praat.call(intensity, \"Get value at time\", timepeaks[following], \"Cubic\")\n",
        "\n",
        "    # Look for only voiced parts\n",
        "    pitch = sound.to_pitch_ac(0.02, 30, 4, False, 0.03, 0.25, 0.01, 0.35, 0.25, 450)\n",
        "    voicedcount = 0\n",
        "    voicedpeak = []\n",
        "\n",
        "    for time in range(validpeakcount):\n",
        "        querytime = validtime[time]\n",
        "        whichinterval = parselmouth.praat.call(textgrid, \"Get interval at time\", 1, querytime)\n",
        "        whichlabel = parselmouth.praat.call(textgrid, \"Get label of interval\", 1, whichinterval)\n",
        "        value = pitch.get_value_at_time(querytime)\n",
        "        if not math.isnan(value):\n",
        "            if whichlabel == \"sounding\":\n",
        "                voicedcount += 1\n",
        "                voicedpeak.append(validtime[time])\n",
        "\n",
        "    # calculate time correction due to shift in time for Sound object versus\n",
        "    # intensity object\n",
        "    timecorrection = originaldur / intensity_duration\n",
        "\n",
        "    # Insert voiced peaks in TextGrid\n",
        "    parselmouth.praat.call(textgrid, \"Insert point tier\", 1, \"syllables\")\n",
        "    for i in range(len(voicedpeak)):\n",
        "        position = (voicedpeak[i] * timecorrection)\n",
        "        parselmouth.praat.call(textgrid, \"Insert point\", 1, position, \"\")\n",
        "\n",
        "    # return results\n",
        "    speakingrate = voicedcount / originaldur\n",
        "    articulationrate = voicedcount / speakingtot\n",
        "    npause = npauses - 1\n",
        "    asd = speakingtot / voicedcount\n",
        "    speechrate_dictionary = {'soundname': file.split('/')[-1],\n",
        "                             'nsyll':voicedcount,\n",
        "                             'npause': npause,\n",
        "                             'dur(s)':originaldur,\n",
        "                             'phonationtime(s)':intensity_duration,\n",
        "                             'speechrate(nsyll / dur)': speakingrate,\n",
        "                             \"articulation rate(nsyll / phonationtime)\":articulationrate,\n",
        "                             \"ASD(speakingtime / nsyll)\":asd}\n",
        "    return speechrate_dictionary\n"
      ],
      "metadata": {
        "id": "mMvIozqymPTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute speech rate\n",
        "speech_rate_list = []\n",
        "for f in female_files:\n",
        "    speechrate_dictionary = speech_rate(file = os.path.join(base_dir, 'female', f))\n",
        "    speech_rate_list.append(speechrate_dictionary)\n",
        "\n",
        "for f in male_files:\n",
        "    speechrate_dictionary = speech_rate(file = os.path.join(base_dir, 'male', f))\n",
        "    speech_rate_list.append(speechrate_dictionary)\n",
        "\n",
        "speech_rate_df = pd.DataFrame(speech_rate_list)\n",
        "\n",
        "speech_rate_df"
      ],
      "metadata": {
        "id": "QyYmzAnXnX3l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}