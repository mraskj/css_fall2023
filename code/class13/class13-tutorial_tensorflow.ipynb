{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mraskj/css_fall2023/blob/main/code/class13/class13-tutorial_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Class 13 - Tutorial - Tensorflow"
      ],
      "metadata": {
        "id": "xsqS4NRY8vg9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This tutorial shows how you can use CNN to classify images. It is based on entirely on the notebook from Michelle Torres: https://colab.research.google.com/drive/1KFHwz8wjDdcFfsTmXfo-gwkKc-itN3MS?usp=%20sharing#scrollTo=4a8Q5WqivZY_ which was used for: https://ds3.ai/courses/imageasdata\n",
        "\n",
        "Note that it uses Tensorflow."
      ],
      "metadata": {
        "id": "VoFRKegr8jPP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2_iTfTwZpmP"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import ZeroPadding2D\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Lambda\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
        "from tensorflow.keras.utils import get_file\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from PIL import Image\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import mnist\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJKIwBYvUjc2"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mh-3V6TVeuQJ"
      },
      "source": [
        "Now, let's import our training and testing dataset to build a model that will allow us to recognize handwritten numbers. We will \"massage\" the data a bit to optimize the process and make it work properly. Tihs means, we will re-shape each image in the training-testing sets (depending on what the set up from Keras is), and we will normalize the pixel intensity so it lies between 0 and 1 (instead of 0 to 255).\n",
        "\n",
        "For the outcome labels, we will convert them from integers to vectors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcNHytUSe0yQ"
      },
      "outputs": [],
      "source": [
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1))\n",
        "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1))\n",
        "\n",
        " # scale data to the range of [0, 1]\n",
        "X_train = X_train.astype(\"float32\") / 255.0\n",
        "X_test = X_test.astype(\"float32\") / 255.0\n",
        "\n",
        "# \"Binarify\" the labels (from categorical to vectors)\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]\n",
        "\n",
        "print(num_classes)\n",
        "print(y_test)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJuaWOdEkvPE"
      },
      "source": [
        "It's time to build our model. What layers can you identify?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXf2BBzWky9y"
      },
      "outputs": [],
      "source": [
        "def large_model():\n",
        "# create model\n",
        "    model = Sequential()\n",
        "    model.add(ZeroPadding2D(padding=(2, 2), input_shape=(28,28,1), data_format=None))\n",
        "    model.add(Conv2D(32, (5, 5), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(50, activation='relu'))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "# Compile model\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adXnx3Jfla8M"
      },
      "source": [
        "And now comes the training and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwQI_zgCldXP"
      },
      "outputs": [],
      "source": [
        "model = large_model()\n",
        "# Fit and train the model using only MNIST data for both training and evaluation\n",
        "H = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=15, batch_size=200)\n",
        "# Final evaluation of the model using MNIST testing data\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBG8W8n--EM-"
      },
      "source": [
        "Let's check some diagnosis:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4RUiC4r-Ohb"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(X_test, batch_size=128)\n",
        "print(predictions[0])\n",
        "print(len(predictions[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1N7UNCyGdXPa"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test.argmax(axis=1),\n",
        "\tpredictions.argmax(axis=1),\n",
        "\ttarget_names=[str(x) for x in np.array(list(range(num_classes)), dtype='uint8')]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBZjhDoABvKx"
      },
      "source": [
        "And the history of loss and accuracy to track overfitting:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5KWvjiXBzht"
      },
      "outputs": [],
      "source": [
        "# A nice function to plot loss and accuracy histories\n",
        "def plot_training(H, N, type=\"loss\"):\n",
        "    # construct a plot that plots and saves the training history\n",
        "    plt.style.use(\"ggplot\")\n",
        "    plt.figure()\n",
        "    if type==\"loss\":\n",
        "        plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "        plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "        plt.title(\"Training vs. Validity Loss\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.legend(loc=\"upper right\")\n",
        "\n",
        "    else:\n",
        "        plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
        "        plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "        plt.title(\"Training vs. Validity Accuracy\")\n",
        "        plt.ylabel(\"Accuracy\")\n",
        "        plt.legend(loc=\"lower right\")\n",
        "    plt.xlabel(\"Epoch #\")\n",
        "\n",
        "\n",
        "plot_training(H, 15)\n",
        "plot_training(H, 15, \"accuracy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65c7dGcRrB3R"
      },
      "source": [
        "Now let's jump to a slightly more complicated but applicable question.\n",
        "\n",
        "We want to classify actual images from protests based on the level of conflict they depict: 1= No conflict, 2= Low conflict, 3= High conflict. The training data contains 400 images that were labeled by 5 different human coders. The testing set has 200 images. All of them come from Getty Images, and are from the BLM protests in Ferguson in 2014.\n",
        "\n",
        "For this classification task, we will use transfer learning. The GPU becomes more necessary here than in the other case because of the size of the data. Let's import our training and testing data for the re-training/transfer learning process:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPX1HDm0Bh9F"
      },
      "outputs": [],
      "source": [
        "train_full = pd.read_csv(\"https://raw.githubusercontent.com/smtorres/Start_Images/main/train_meta.csv\")\n",
        "test_full = pd.read_csv(\"https://raw.githubusercontent.com/smtorres/Start_Images/main/test_meta.csv\")\n",
        "\n",
        "print(train_full)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S23LM69EqHer"
      },
      "source": [
        "Almost always you will have to clean up your data and make sure you have the correct labels in the correct format. In this case, we will simply make sure that the labels are of type \"string\" given the specifications of the CNN model we will train. Note that our outcome of interest is \"ConfCode\" (level of conflict). We are also load all of our images in an array that will feed the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKs15v4HFZ6x"
      },
      "outputs": [],
      "source": [
        "to_res = (256, 256)\n",
        "\n",
        "files_train = train_full['ImgFile']\n",
        "files_test = test_full['ImgFile']\n",
        "core_url = \"https://github.com/smtorres/Start_Images/blob/main/\"\n",
        "\n",
        "train_imgs = []\n",
        "for i in files_train:\n",
        "  turl = core_url+\"train/\"+i+\"?raw=true\"\n",
        "  image_url = get_file(origin=turl)\n",
        "  img = load_img(image_url, target_size=to_res)\n",
        "  img = np.array(img)\n",
        "  #img = img/255\n",
        "  train_imgs.append(img)\n",
        "  del turl,image_url,img\n",
        "\n",
        "train_imgs_mat = np.array(train_imgs)\n",
        "train_labels = train_full['ConfCode'].to_list()\n",
        "train_labels= [str(x) for x in train_labels]\n",
        "\n",
        "test_imgs = []\n",
        "for i in files_test:\n",
        "  turl = core_url+\"test/\"+i+\"?raw=true\"\n",
        "  image_url = get_file(origin=turl)\n",
        "  img = load_img(image_url, target_size=to_res)\n",
        "  img = np.array(img)\n",
        "  #img = img/255\n",
        "  test_imgs.append(img)\n",
        "  del turl,image_url,img\n",
        "  print(str(i))\n",
        "\n",
        "test_imgs_mat = np.array(test_imgs)\n",
        "test_labels = test_full['ConfCode'].to_list()\n",
        "test_labels = [str(x) for x in test_labels]\n",
        "\n",
        "print('Train dataset shape:', train_imgs_mat.shape,\n",
        " '\\tValidation dataset shape:', test_imgs_mat.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBtld8t5dKLG"
      },
      "source": [
        "We will also have to clean and manipulate the images. In this case, by normalizing them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCoFwbHlsNbV"
      },
      "outputs": [],
      "source": [
        "train_imgs_scaled =train_imgs_mat/ 255\n",
        "test_imgs_scaled = test_imgs_mat/255\n",
        "\n",
        "train_labels_enc = to_categorical(train_labels)\n",
        "\n",
        "test_labels_enc = to_categorical(test_labels)\n",
        "\n",
        "# visualize a sample image\n",
        "print(train_imgs_mat[0].shape)\n",
        "print(test_labels[:5])\n",
        "array_to_img(train_imgs_mat[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pm6uQj6pqhWG"
      },
      "source": [
        "Now, let's begin with the fun! Our work flow includes the following:\n",
        "\n",
        "1) Import a pre-trained model from Keras (in this case, a lovely ResNet50)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAGPk1rYsVQz"
      },
      "outputs": [],
      "source": [
        "input_t = Input(shape=(256, 256, 3)) # The size of the images that we want the model to take. In this case 256 x 256 pixels (*)\n",
        "res_model = ResNet50(weights=\"imagenet\", input_tensor = input_t) # Import the canned model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C69Ze-EbtYI7"
      },
      "source": [
        "Let's explore the architecture and what's inside our model..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdmR3n7BtiPD"
      },
      "outputs": [],
      "source": [
        "for i,layer in enumerate(res_model.layers):\n",
        "\tprint(i, layer.name, \"-\", layer.trainable)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rf3X6OI1GfxI"
      },
      "source": [
        "Notice how all layers are trainable, meaning, we are using the FULL architecture, including the original labels, to potentially classify some pictures."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3givA1huF_E"
      },
      "source": [
        "Great! It seems like it works... let's import the model again but now without the head (e.g. the pre-canned labels)\n",
        "\n",
        "2) And then, let's \"freeze\" some layers, meaning, make them forget what they learned when the CNN was trained with the Imagenet dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVi9fvTJuRnN"
      },
      "outputs": [],
      "source": [
        "model = ResNet50(include_top=False, weights=\"imagenet\", input_tensor = input_t) # Import the canned model\n",
        "\n",
        "for layer in res_model.layers[:143]:\n",
        "\tlayer.trainable = False\n",
        "\n",
        "# Sanity check to see if it worked!\n",
        "for i,layer in enumerate(res_model.layers):\n",
        "\tprint(i, layer.name, \"-\", layer.trainable)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMb_v4m-vFuP"
      },
      "source": [
        "3) Modify the architecture of the pre-trained model according to your needs. Note that we did a LOT with this model. Let's go through some of the components:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKodF0c7kU55"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(ResNet50(include_top = False, pooling = 'avg', weights = 'imagenet', input_tensor=input_t))\n",
        "\n",
        "model.add(Dense(3, activation = 'softmax'))\n",
        "\n",
        "# Say not to train first layer (ResNet) model as it is already trained\n",
        "model.layers[0].trainable = False\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOWjkBkcxp6T"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer = Adam(learning_rate=0.001), loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tx2wv3X5vLb8"
      },
      "source": [
        "4) Get our training data ready! This implies resizing (to fit the input of the original model we are using), normalizing, and \"augmenting\" the images in our set. This augmentation is a cool trick: it flips, turns, and modifies the images in our dataset so the CNN \"learns\" different variations of the same model. It is the cheapest way of enlarging your training data!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4a8Q5WqivZY_"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(zoom_range=0.3, rotation_range=50,\n",
        " width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2,\n",
        " horizontal_flip=True, fill_mode='nearest')\n",
        "\n",
        "test_datagen = ImageDataGenerator()\n",
        "\n",
        "train_generator = train_datagen.flow(train_imgs_mat, train_labels_enc,batch_size=30)\n",
        "test_generator = test_datagen.flow(test_imgs_mat, test_labels_enc, batch_size=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCJK6dFFv98-"
      },
      "source": [
        "5) Train our model with our images of interest... be patient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXF1RoZFwFOj"
      },
      "outputs": [],
      "source": [
        "history = model.fit(train_generator,epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMViV76MyXp0"
      },
      "source": [
        "6) ...and assess accuracy, mistakes, loss values, diagnostic plots, etc. until we are comfortable with the results (this does not mean, until we get the result we want but until we have some strong evidence that the model is correctly doing what we envisioned it should do!)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjdNB7Gh7ls0"
      },
      "outputs": [],
      "source": [
        "preds = model.predict(test_generator)\n",
        "y_int_pred = np.argmax(preds,axis=1)\n",
        "print(preds[0:10])\n",
        "print(y_int_pred[0:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZulXKWwAzV_"
      },
      "outputs": [],
      "source": [
        "model.evaluate(test_generator, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqG_ykeubXx9"
      },
      "outputs": [],
      "source": [
        "y_true=[int(x) for x in test_labels]\n",
        "print(confusion_matrix(y_true, y_int_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWJXC9F_Cwzy"
      },
      "source": [
        "7) Save the coefficients (errh... weights) of your model so you can predict out-of-sample labels --> Our ultimate objective!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n71sTe07yjKY"
      },
      "outputs": [],
      "source": [
        "model.save_weights(base_direc+\"Model/tuned_weights_trust\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}